{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data & ML @Go-Jek \n",
    "\n",
    "### 3 December 2018, 7:35pm - 8:05pm\n",
    "\n",
    "#### Guo Jun\n",
    "#### Data Science, Gojek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Content\n",
    "\n",
    "1. The problem of surge pricing\n",
    "2. Why we needed clustering for better surge\n",
    "3. Why we picked python to write the clustering service\n",
    "4. What we learnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The problem of surge pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why Surge Pricing?\n",
    "\n",
    "1. Helps ensure a reliable service.\n",
    "2. Defend for our supply of drivers.\n",
    "\n",
    "Surge is the manipulating in real time situation of market (demand & supply)\n",
    "disequilibrium to bring market back to equilibrium.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Economics 101\n",
    "![Economics 101](assets/surge_econ.jpg)\n",
    "\n",
    "We maximise number of completed bookings when we set price at P*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our initial version of surge\n",
    "\n",
    "Applies a formula on spaces divided into buckets of grid shape where the main inputs are demand and supply of the area.\n",
    "Looks something like this:\n",
    "\n",
    "![Naive Surge](assets/naive_surge.png)\n",
    "\n",
    "It actually works pretty a-okay!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why we needed clustering for better surge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What are some issues?\n",
    "\n",
    "* Easily hackable (Walk to the next street etc...)\n",
    "\n",
    "![Surge Hacking 1](assets/surge_hacking_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Surge Hacking 2](assets/surge_hacking_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We need to find a way to group similar \"geospatial buckets\" sounds like a clustering problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Clustering constraints\n",
    "\n",
    "* Clusters must be spatially contiguous.\n",
    "* Larger clusters on the outskirts of the city where information are more sparse and erratic to pool together the information for more efficient surge-pricing.\n",
    "* Dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Clustering\n",
    "![Clusters](assets/clusters.png)\n",
    "\n",
    "<center>Credits: Peter Richens</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>Check out his medium post about how we do allocation!</center>\n",
    "\n",
    "![Jaeger](assets/jaeger.jpeg)\n",
    "\n",
    "https://blog.gojekengineering.com/how-we-use-machine-learning-to-match-drivers-riders-b06d617b9e5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cluster surge\n",
    "\n",
    "This is how the initial formula works on the cluster level:\n",
    "\n",
    "![cluster surge](assets/cluster_surge.png)\n",
    "\n",
    "Looks awesome! Let's take it deploy this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why we picked python to write the clustering service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Shall we do it in python?\n",
    "\n",
    "1. The EDA already done in python. Jupyter <3\n",
    "2. Pre-built machine learning libraries\n",
    "3. Data scientists are more usually more familiar with Python — easier to debug\n",
    "\n",
    "Seems like a no brainer..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Let's get started...\n",
    "\n",
    "**First question**: \n",
    "Python 2 or 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Headache](assets/Jackie-Chan-WTF.jpg)\n",
    "<center>Having a headache already...</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Second question**: \n",
    "How do we manage dependencies and environment?\n",
    "\n",
    "* pyenv + pipenv?\n",
    "* conda?\n",
    "* pyenv + conda?\n",
    "* pip + virtualenv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Python Environment](assets/xkcd_python_environment_2x.png)\n",
    "\n",
    "<center>“Python Environment” by xkcd</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Third question**: \n",
    "Seems like we have to maintain the features in our service. Do we have a database migration strategy for it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How do we monitor the webservice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Do we have a rollback strategy for a bad model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What we learnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Are you ready to deploy a python model? :)\n",
    "\n",
    "Most of the time, it might be easier to work with a language that your organization is more familiar with. \n",
    "\n",
    "If so... here are some of the things my team learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A project structure \n",
    "\n",
    "A standardize way of managing python project and environment. \n",
    "Making it reproducible across machines and amongst the team. \n",
    "You just have to do it once. \n",
    "\n",
    "Project structure for this presentation\n",
    "```\n",
    "❯ tree\n",
    ".\n",
    "├── Makefile                     <- Makefile with commands like `make present`\n",
    "├── README.md                    <- The top-level README for developers using this project.\n",
    "├── environment.yaml             <- The specification files to build a conda environment \n",
    "└── notebooks                    <- Jupyter notebooks for this presentation.\n",
    "    ├── assets                   <- Assets to store images, video.\n",
    "    │   ├── cluster_surge.png\n",
    "    │   ├── clusters.png\n",
    "    │   ├── naive_surge.png\n",
    "    │   ├── osm_vector_small.png\n",
    "    │   ├── surge_econ.jpg\n",
    "    │   └── xkcd_python_environment_2x.png\n",
    "    ├── main.ipynb\n",
    "    └── main.slides.html\n",
    "```\n",
    "\n",
    "pyenv + conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Checkout cookiecutter data science for some inspiration\n",
    "\n",
    "```\n",
    "├── LICENSE\n",
    "├── Makefile           <- Makefile with commands like `make data` or `make train`\n",
    "├── README.md          <- The top-level README for developers using this project.\n",
    "├── data\n",
    "│   ├── external       <- Data from third party sources.\n",
    "│   ├── interim        <- Intermediate data that has been transformed.\n",
    "│   ├── processed      <- The final, canonical data sets for modeling.\n",
    "│   └── raw            <- The original, immutable data dump.\n",
    "│\n",
    "├── docs               <- A default Sphinx project; see sphinx-doc.org for details\n",
    "│\n",
    "├── models             <- Trained and serialized models, model predictions, or model summaries\n",
    "│\n",
    "├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n",
    "│                         the creator's initials, and a short `-` delimited description, e.g.\n",
    "│                         `1.0-jqp-initial-data-exploration`.\n",
    "│\n",
    "├── references         <- Data dictionaries, manuals, and all other explanatory materials.\n",
    "│\n",
    "├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n",
    "│   └── figures        <- Generated graphics and figures to be used in reporting\n",
    "│\n",
    "├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.\n",
    "│                         generated with `pip freeze > requirements.txt`\n",
    "│\n",
    "├── setup.py           <- Make this project pip installable with `pip install -e`\n",
    "├── src                <- Source code for use in this project.\n",
    "│   ├── __init__.py    <- Makes src a Python module\n",
    "│   │\n",
    "│   ├── data           <- Scripts to download or generate data\n",
    "│   │   └── make_dataset.py\n",
    "│   │\n",
    "│   ├── features       <- Scripts to turn raw data into features for modeling\n",
    "│   │   └── build_features.py\n",
    "│   │\n",
    "│   ├── models         <- Scripts to train models and then use trained models to make\n",
    "│   │   │                 predictions\n",
    "│   │   ├── predict_model.py\n",
    "│   │   └── train_model.py\n",
    "│   │\n",
    "│   └── visualization  <- Scripts to create exploratory and results oriented visualizations\n",
    "│       └── visualize.py\n",
    "│\n",
    "└── tox.ini            <- tox file with settings for running tox; see tox.testrun.org\n",
    "```\n",
    "\n",
    "https://drivendata.github.io/cookiecutter-data-science/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Python style guide\n",
    "\n",
    "Defining a team style guide early, makes python code more readable and code documentation easier.\n",
    "\n",
    "Doctest is super helpful! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "File \"__main__\", line 16, in NoName\n",
      "Failed example:\n",
      "    add_five(x)\n",
      "Expected:\n",
      "    21    \n",
      "Got:\n",
      "    25\n"
     ]
    }
   ],
   "source": [
    "def add_five(i):\n",
    "    \"\"\"Dummy function to add five to integer\n",
    "    \n",
    "    Args:\n",
    "      i (int):\n",
    "          Input integer\n",
    "          \n",
    "    Returns:\n",
    "      int: input integer + 5\n",
    "      \n",
    "    Example:\n",
    "      >>> i = 5\n",
    "      >>> add_five(i)\n",
    "      10\n",
    "      >>> x = 20\n",
    "      >>> add_five(x)\n",
    "      21    \n",
    "    \"\"\"\n",
    "    return i + 5\n",
    "\n",
    "import doctest\n",
    "doctest.run_docstring_examples(add_five, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Environment Config\n",
    "\n",
    "Be careful..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "x = os.getenv('FOO')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FOO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2e9b2f538adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FOO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/gojek-geospatial-clustering-presentation/lib/python3.6/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FOO'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "x = os.environ['FOO']\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Start a python internal library\n",
    "\n",
    "You will be surprised how many people are actually solving the same problem on the same team... \n",
    "\n",
    "* Pulling and pushing data to database\n",
    "* Data visualization (Customizing your matplotlib)\n",
    "* Common utils\n",
    "\n",
    "https://matplotlib.org/users/customizing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Config package \n",
    "def get_string_list_or_raise_exception(key):\n",
    "    \"\"\"Get env string from key and split by comma\n",
    "    \n",
    "    Args:\n",
    "      key (str):\n",
    "          Input env key\n",
    "          \n",
    "    Returns:\n",
    "      list:\n",
    "          Env value split by comma\n",
    "      \n",
    "    Example:\n",
    "      >>> \n",
    "      >>> get_string_list_or_raise_exception(\"\")\n",
    "      10    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        value = os.environ[key].split(',')\n",
    "        return value\n",
    "    except Exception as err:\n",
    "        logging.error(\"Error getting string value from key: %s\", err)\n",
    "        raise err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiprocessing\n",
    "\n",
    "Could consider multiprocessing to side step the Global Interpreter Lock if you need concurrency. \n",
    "\n",
    "At this point, I would also consider a more performance language... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "Take steps to build:\n",
    "* A reproducible development environment\n",
    "* Common toolkit for the team\n",
    "* Idiomatic style guide for readability\n",
    "\n",
    "Consider:\n",
    "* Throughput and latency\n",
    "* Organization's familiarity with the language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank You 🐍"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
